{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32479668-64ec-46fb-a820-91ad9c7e4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0eda9c-288a-496d-b4f1-545cfa06da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "mini_batch_size = 128\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc98d599-7afc-47d6-9856-cadf50ef344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\\\n",
    "                transforms.Resize((32,32)),\\\n",
    "                transforms.ToTensor(),\\\n",
    "                transforms.Normalize(mean = (0.1307,), std = (0.3081,))\\\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\\\n",
    "                transforms.Resize((32,32)),\\\n",
    "                transforms.ToTensor(),\\\n",
    "                transforms.Normalize(mean = (0.1325,), std = (0.3105,))\\\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(torchvision.datasets.MNIST('data/',train=True, download=True, transform=train_transforms),batch_size=mini_batch_size)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('data/',train=False, download=True, transform=test_transforms), batch_size=mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4651245-cd37-4f3d-90f7-e5c76961cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(OrderedDict([\n",
    "            ('c1' , nn.Conv2d(1,6, kernel_size=(5,5),) ),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('s2', nn.MaxPool2d(kernel_size=(2,2), stride=2)),\n",
    "            ('c3', nn.Conv2d(6, 16, kernel_size=(5,5), )),\n",
    "            ('relu2' , nn.ReLU()),\n",
    "            ('s4', nn.MaxPool2d(kernel_size=(2,2), stride=2)) ,\n",
    "            ('c5', nn.Conv2d(16, 120, kernel_size=(5,5)) ),\n",
    "            ('relu3', nn.ReLU() ),]\n",
    "        ))\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('f6', nn.Linear(120, 84) ),\n",
    "            ('relu6', nn.ReLU() ),\n",
    "            ('f7', nn.Linear(84,10) ),\n",
    "            ('sig7', nn.LogSoftmax(dim=-1) )\n",
    "            ]\n",
    "        ))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convnet(x)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9068b1a0-f4ab-42ab-bb0d-9046011b5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTraining:\n",
    "\n",
    "    def __init__(self, classifer_model, train_loader: DataLoader, test_loader: DataLoader, prune_version=None):\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = classifer_model.to(self.device)\n",
    "        # self.model.to(self.device)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        self.train_losses = []\n",
    "        self.train_counter = []\n",
    "        self.test_counter = []\n",
    "        self.test_losses = []\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        if prune_version is None:\n",
    "            self.version = 'base'\n",
    "        else:\n",
    "            self.version = prune_version\n",
    "\n",
    "    def train(self, epoch, verbose=True):\n",
    "        print(self.device)\n",
    "        os.makedirs('results/',exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data,target) in enumerate(train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target) # cross entropy loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                if verbose:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(self.train_loader.dataset),\\\n",
    "                        100. * batch_idx / len(self.train_loader), loss.item()))\n",
    "                self.train_losses.append(loss.item())\n",
    "                self.train_counter.append(\n",
    "                    (batch_idx * 128) + ((epoch - 1) * len(self.train_loader.dataset)))\n",
    "                torch.save(self.model.state_dict(), f'results/model_{self.version}.pth')\n",
    "                torch.save(self.optimizer.state_dict(), f'results/optimizer_{self.version}.pth')\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += F.nll_loss(output, target, size_average=True).item()\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        test_loss /= len(self.test_loader.dataset)\n",
    "        self.test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(self.test_loader.dataset),\n",
    "            100. * correct / len(self.test_loader.dataset)))\n",
    "\n",
    "    def train_model(self,n_epoch):\n",
    "        train_start_dt = datetime.now()\n",
    "        self.test_counter = [i * len(self.train_loader.dataset) for i in range(n_epoch)]\n",
    "\n",
    "        for ep in range(1, n_epoch+1):\n",
    "            self.train(ep)\n",
    "            self.test()\n",
    "        train_end_dt = datetime.now()\n",
    "        train_duration = (train_end_dt-train_start_dt)\n",
    "\n",
    "        print(f\"Total Training Time : {train_duration}\")\n",
    "        self.plot_train_test()\n",
    "\n",
    "    def plot_train_test(self):\n",
    "        fig = plt.figure()\n",
    "        plt.plot(self.train_counter, self.train_losses, color='blue')\n",
    "        plt.scatter(self.test_counter, self.test_losses, color='red')\n",
    "        plt.legend(['Training Loss', 'Test Loss'], loc='upper right')\n",
    "        plt.xlabel('No of Training Samples')\n",
    "        plt.ylabel('Loss Function (NLL)')\n",
    "        fig.savefig(f'results/training_curve_{self.version}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77ece0a1-e581-47c9-b93a-a3ea8bbc081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_model = LeNet()\n",
    "\n",
    "prune_model.load_state_dict(torch.load('results/model_base.pth'))\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (prune_model.convnet.c1,'weight'),\n",
    "    (prune_model.convnet.c3,'weight'),\n",
    "    (prune_model.convnet.c5,'weight'),\n",
    "    (prune_model.fc.f6,'weight'),\n",
    "    (prune_model.fc.f7,'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.RandomUnstructured,\n",
    "    amount=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "prune.remove(prune_model.convnet.c1,'weight')\n",
    "prune.remove(prune_model.convnet.c3,'weight')\n",
    "prune.remove(prune_model.convnet.c5,'weight')\n",
    "prune.remove(prune_model.fc.f6,'weight')\n",
    "prune.remove(prune_model.fc.f7,'weight')\n",
    "\n",
    "pruned_classifer = ClassifierTraining(classifer_model=prune_model, train_loader=train_loader, test_loader=test_loader)\n",
    "pruned_classifer.train_model(n_epoch=n_epochs)\n",
    "\n",
    "pruned_params = get_pruned_parameters_count(prune_model)\n",
    "print('Original Model paramete count:', total_params_count)\n",
    "print('Pruned Model parameter count:', pruned_model_param_count)\n",
    "print(f'Compressed Percentage: {(100 - (pruned_model_param_count / total_params_count) * 100)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
